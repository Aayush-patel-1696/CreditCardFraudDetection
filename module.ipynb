{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mango.tuner import Tuner\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import average_precision_score,classification_report,roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "from sklearn.model_selection import train_test_split, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSampling:\n",
    "\n",
    "    def __init__(self,df,y_column,test_size,random_state,stratify=True,shuffle=True):\n",
    "        self.df = df\n",
    "        self.random_state = 42\n",
    "        self.y_column = y_column\n",
    "        self.test_size =test_size\n",
    "        self.random_state = random_state\n",
    "        self.stratify = stratify\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        def data_train_test_split():\n",
    "\n",
    "            self.X,self.y = self.df[list(set(self.df.columns).difference([self.y_column]))],self.df[self.y_column]\n",
    "            if stratify == True:\n",
    "                self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X,self.y, test_size=self.test_size,shuffle=self.shuffle,stratify=self.y)\n",
    "            else:\n",
    "                self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X,self.y, test_size=test_size,shuffle=shuffle)\n",
    "\n",
    "        data_train_test_split()\n",
    "\n",
    "    \n",
    "    def get_data_wthout_sample(self):\n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "    \n",
    "    def get_data_smote(self):\n",
    "        sm = SMOTE(random_state=self.random_state)\n",
    "        X_sm, y_sm = sm.fit_resample(self.X_train, self.y_train)\n",
    "        return X_sm,self.X_test,y_sm,self.y_test\n",
    "\n",
    "    def get_data_near_miss(self,sampling_strategy=0.1):\n",
    "        nm = NearMiss(sampling_strategy=sampling_strategy)\n",
    "        X_nm,y_nm = nm.fit_resample(self.X_train,self.y_train)\n",
    "        return X_nm,self.X_test,y_nm,self.y_test\n",
    "       \n",
    "    def get_data_random_over_sample(self):\n",
    "        os =  RandomOverSampler(random_state=self.random_state)\n",
    "        X_os,y_os = os.fit_resample(self.X_train,self.y_train) \n",
    "        return X_os,self.X_test,y_os,self.y_test\n",
    "\n",
    "    def print_class_percentage(self,X_train,X_test,y_train,y_test):\n",
    "\n",
    "        print(\"----Train class count------\")\n",
    "        y_tr_cnts = y_train.value_counts()\n",
    "        print(y_tr_cnts)\n",
    "        print(y_tr_cnts/sum(y_tr_cnts))\n",
    "        print(\"----Test class count------\")\n",
    "        y_ts_cnts = y_test.value_counts()\n",
    "        print(y_ts_cnts)\n",
    "        print(y_ts_cnts/sum(y_ts_cnts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "ds = DataSampling(df,\"Class\",0.30,42,True,True)\n",
    "X_nm_train,X_test,y_nm_train,y_test= ds.get_data_near_miss()\n",
    "X_train,X_test,y_train,y_test = ds.get_data_wthout_sample()\n",
    "# X_nm_train,y_nm_train= ds.get_data_random_over_sample()\n",
    "# X_sm_train,y_sm_train= ds.get_data_smote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Train class count------\n",
      "Class\n",
      "0    3440\n",
      "1     344\n",
      "Name: count, dtype: int64\n",
      "Class\n",
      "0    0.909091\n",
      "1    0.090909\n",
      "Name: count, dtype: float64\n",
      "----Test class count------\n",
      "Class\n",
      "0    85295\n",
      "1      148\n",
      "Name: count, dtype: int64\n",
      "Class\n",
      "0    0.998268\n",
      "1    0.001732\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ds.print_class_percentage(X_nm_train,X_test,y_nm_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianOpt:\n",
    "\n",
    "    def __init__(self,classifier):\n",
    "        self.classifier = classifier\n",
    "        self.optimize_results = None\n",
    "       \n",
    "\n",
    "    def _fit(self,X_train,y_train,params):\n",
    "        \"\"\"\n",
    "        Internal Function for bayesian Optimization\n",
    "        \"\"\"\n",
    "        # Initialize Classifier\n",
    "        clf = self.classifier\n",
    "\n",
    "        # Extract Realted Params for Classifier\n",
    "        validated_params = {}\n",
    "        param_cls = clf.get_params().keys()\n",
    "        for key in params:\n",
    "            if key in param_cls:\n",
    "                validated_params[key] = params[key]\n",
    "            else:\n",
    "                pass\n",
    "        clf.set_params(**validated_params)\n",
    "        \n",
    "        return clf.fit(X_train,y_train)   \n",
    "    \n",
    "    def optimize(self,X_train,y_train,param_grid,conf_dict):\n",
    "\n",
    "        \"\"\"\n",
    "        Optimization Function for classifier with data inputs and scoring function\n",
    "        \"\"\"\n",
    "        def objective(args_list):\n",
    "            accuracies = []\n",
    "            for params in args_list:\n",
    "                \n",
    "                # Fit the model\n",
    "                clf = self._fit(X_train,y_train,params)\n",
    "\n",
    "                # Evaluate the model with cross validation\n",
    "                accuracy = cross_validate(clf, X_train, y_train, cv=params[\"cv\"], scoring=params[\"scoring\"],n_jobs=params[\"n_jobs\"])\n",
    "                accuracies.append(np.mean(accuracy[\"test_score\"]))\n",
    "\n",
    "            return accuracies\n",
    "\n",
    "        tuner_user = Tuner(param_grid, objective, conf_dict)\n",
    "        optimize_results = tuner_user.maximize()\n",
    "        self.optimize_results = optimize_results\n",
    "        return optimize_results\n",
    "    \n",
    "    \n",
    "    def optimize_fit(self,X_train,y_train,param_grid,conf_dict):\n",
    "        \"\"\"\n",
    "        Optimization and Function for classifier with data inputs and scoring function\n",
    "        Returns fitted object for the classifier\n",
    "        \"\"\"\n",
    "        optimized_results = self.optimize(X_train,y_train,param_grid,conf_dict)\n",
    "        return self._fit(X_train,y_train,optimized_results[\"best_params\"])\n",
    "\n",
    "def publish_model_socres(X,y,cv_fit,plotting=True):\n",
    "    y_pred=cv_fit.predict(X)\n",
    "    y_pred_prob = cv_fit.predict_proba(X)\n",
    "    print(classification_report(y,y_pred))\n",
    "    print(\"ROC_AUC Score\",roc_auc_score(y,y_pred_prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "ds = DataSampling(df,\"Class\",0.30,42,True,True)\n",
    "X_train,X_test,y_train,y_test = ds.get_data_wthout_sample()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the data with specified hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specified the parameters\n",
    "param_grid = { 'criterion':['gini','entropy'],\n",
    "              'max_depth': np.arange(1,15),\n",
    "              \"max_features\": ['sqrt', 'log2'],\n",
    "              \"min_samples_split\": range(2,21),\n",
    "              \"class_weight\": [{0:1, 1:1}, {0:1, 1:5}, {0:1, 1:50},'balanced'],\n",
    "              \"cv\":[2],\"scoring\":[\"f1_macro\"],\"n_jobs\":[-1]}\n",
    "\n",
    "# Config dict for Bayesian Optimizer\n",
    "conf_dict={\"num_iteration\":100}\n",
    "\n",
    "# Fit and Optimize the Baysian model\n",
    "dt_opt = BayesianOpt(DecisionTreeClassifier(random_state = 0))\n",
    "best_model = dt_opt.optimize_fit(X_train,y_train,param_grid,conf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model on seen and unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Training model Results------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    199020\n",
      "           1       0.89      0.72      0.80       344\n",
      "\n",
      "    accuracy                           1.00    199364\n",
      "   macro avg       0.95      0.86      0.90    199364\n",
      "weighted avg       1.00      1.00      1.00    199364\n",
      "\n",
      "ROC_AUC Score 0.9404008420329382\n",
      "------Testing model Result----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.90      0.66      0.76       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.95      0.83      0.88     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "ROC_AUC Score 0.9178098111007427\n"
     ]
    }
   ],
   "source": [
    "print(\"------Training model Results------\")\n",
    "publish_model_socres(X_train,y_train,best_model)\n",
    "print(\"------Testing model Result----------\")\n",
    "publish_model_socres(X_test,y_test,best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
